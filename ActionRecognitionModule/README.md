# PillowMate 행동 인식 모듈 (Action Recognition Module)

Velostat 압력센서와 MPU6050 IMU를 결합해 PillowMate가 사용자의 물리적 상호작용(토닥, 눕기, 껴안기, 흔들기)을 분류하는 서브 모듈입니다. 이 디렉토리에는 아두이노 데이터 수집 스케치, Python 기반 학습 파이프라인, 그리고 실시간 추론 스케치가 함께 들어 있습니다.

## Repository Map

```
arduino/
  action_module_data_logger/      # Streams raw sensors for dataset collection
  action_module_inference/        # Runs the trained classifier in real time
    model_params.h             # Auto-generated weights (placeholder included)
python/
  collect_data.py              # Interactive serial logger with labels
  train_model.py               # Trains logistic regression + exports headers
  requirements.txt             # Python dependencies
data/
  raw/                         # CSV recordings (created by collect_data.py)
  processed/                   # Optional feature-engineering space
models/
  model_params.json            # Saved weights/metadata from training
```

## Hardware + Libraries

* Arduino-compatible board with at least one analog pin and I2C (e.g., Nano 33 BLE, Feather, Uno + USB).
* Velostat (or any pressure-sensitive resistor) wired as a simple voltage divider feeding `A0`.
* Adafruit MPU-6050 (or compatible) IMU connected via I2C.
* Optional NeoPixel strip/ring on pin D9 for visual feedback.
* Arduino libraries: `Adafruit_MPU6050`, `Adafruit_Sensor`, `Adafruit_NeoPixel`.

## 1. Collect Training Data

1. Flash `arduino/action_module_data_logger/action_module_data_logger.ino`.
2. Connect via USB; confirm the Serial Monitor prints CSV lines.
3. Install Python deps once:
   ```bash
   cd ActionRecognitionModule/python
   python -m venv .venv && source .venv/bin/activate
   pip install -r requirements.txt
   ```
4. Run the logger, specifying your serial port:
   ```bash
   python collect_data.py --port /dev/ttyACM0 --duration 6 --trials 3
   ```
   *The script guides you through each label (`tap`, `rest_head`, `hug`, `shake`). Press Enter to start each recording window while performing the interaction.*
5. Repeat sessions until you have balanced coverage inside `data/raw`.

## 2. Train + Export the Classifier

1. Stay in `ActionRecognitionModule/python` (with the virtual environment active).
2. Run:
   ```bash
   python train_model.py
   ```
3. Outputs:
   * `models/model_params.json` – weights, bias, scaler statistics, labels.
   * `arduino/action_module_inference/model_params.h` – C header consumed by the inference sketch.
4. Inspect the printed classification report to confirm performance. Collect more data if needed.

## 3. Deploy Real-Time Inference

1. Open `arduino/action_module_inference/action_module_inference.ino`.
2. Confirm `model_params.h` now contains non-zero weights (re-generated by the trainer).
3. Set `kUseNeoPixel` to `false` if you do not have LEDs connected.
4. Flash the sketch. The Serial Monitor will print predicted labels whenever they change, and the NeoPixel colors will update (`tap` = blue, `rest_head` = green, `hug` = pink, `shake` = amber).

## How It Works

* **Features:** `[pressure_delta, ax, ay, az, gx, gy, gz]`.
* **Model:** Multinomial logistic regression trained with scikit-learn, standardized via a z-score scaler.
* **Arduino runtime:** Streams sensors at ~60 Hz, averages the last 8 samples to reduce noise, then calls `ActionModuleModel::predict()` (generated code) to pick the highest logit.

## Customization Tips

* **Different IMU:** Update both sketches to use the appropriate library but keep the CSV column order identical.
* **More labels:** Pass `--labels tap rest_head hug shake squeeze ...` to `collect_data.py`, retrain, and the pipeline adapts automatically.
* **Sampling rate tweaks:** Adjust `kSampleDelayMs` in both Arduino sketches for faster or slower acquisition (ensure the Python script can keep up).
* **Data curation:** Move merged/cleaned CSVs into `data/processed` if you add manual feature engineering before training.

## Troubleshooting

* Blank CSVs → check that the Arduino serial monitor shows numeric lines and the correct port is passed to `collect_data.py`.
* Model predicts only one label → gather more balanced data or ensure that `pressureBaseline` is calibrated while the pillow is untouched.
* Compilation fails complaining about `model_params.h` → rerun `python/train_model.py` to regenerate the header after collecting data.

Happy building! Both sketches are heavily commented so you can tinker even if you are new to Arduino. If you make wiring or hardware changes, just keep the CSV format stable so the ML side remains plug-and-play.
