import fs from "fs";
import mic from "mic";
import WaveFilePackage from "wavefile";
import { updateMicDisplay, attachStatusDisplay } from "./status_display.js";
const { WaveFile } = WaveFilePackage;

const SAMPLE_RATE = 16000;
const CHANNELS = 1;
const BIT_DEPTH = 16;
const BYTES_PER_SAMPLE = (BIT_DEPTH / 8) * CHANNELS;

function computeRms(buffer) {
  if (!buffer || buffer.length === 0) {
    return 0;
  }
  let sumSquares = 0;
  const sampleCount = buffer.length / BYTES_PER_SAMPLE;
  for (let i = 0; i < buffer.length; i += 2) {
    const sample = buffer.readInt16LE(i);
    sumSquares += sample * sample;
  }
  const rms = Math.sqrt(sumSquares / sampleCount);
  return rms / 32768;
}

function renderLevel(level, { active = true } = {}) {
  if (!active) {
    updateMicDisplay("ğŸ§ ìŒì„± ì…ë ¥ ëŒ€ê¸° ì¤‘...");
    return;
  }
  const clamped = Math.max(0, Math.min(1, level));
  const barLength = 30;
  const filled = Math.round(clamped * barLength);
  updateLedForLevel(clamped);
  const micLine = `ğŸ™ Input [${"â–ˆ".repeat(filled).padEnd(barLength, " ")}] ${(
    clamped * 100
  ).toFixed(0)}%`;
  updateMicDisplay(micLine);
}

let ledAdapter = null;
let lastLedLevel = 0;

export function registerLedAdapter(adapter) {
  ledAdapter = adapter;
}

function updateLedForLevel(level) {
  // ìµœê·¼ ì…ë ¥ê°’ê³¼ ê²°í•©í•´ LED ë°ê¸° ë³€í™”ê°€ ë¶€ë“œëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ í•œë‹¤.
  const eased = lastLedLevel * 0.7 + level * 0.3;
  lastLedLevel = eased;
  const brightness = Math.round(Math.min(1, Math.max(0, eased)) * 255);
  // ê°„ë‹¨í•œ ì»¬ëŸ¬ ë§µ: ë‚®ì€ ì…ë ¥ì€ íŒŒë€ë¹›, ì¤‘ê°„ ì…ë ¥ì€ ë…¹ìƒ‰/ì²­ë¡, ë†’ì€ ì…ë ¥ì€ ì£¼í™©ë¹›ìœ¼ë¡œ í‘œí˜„
  const color =
    brightness < 85
      ? [0, 0, brightness]
      : brightness < 170
        ? [0, brightness, brightness / 2]
        : [brightness, 50, 0];
  const payload = { brightness, color };
  if (ledAdapter && typeof ledAdapter.setState === "function") {
    // ì‹¤ì œ LED ì–´ëŒ‘í„°ê°€ ì£¼ì…ëœ ê²½ìš°, í•´ë‹¹ ì¥ì¹˜ì— ìƒíƒœ ì „ë‹¬
    ledAdapter.setState(payload);
  } else {
    return;
  }
}

export function recordAudio(outputFile, options = {}) {
  return new Promise((resolve, reject) => {
    attachStatusDisplay();
    const startThreshold = options.startThreshold ?? 0.02;
    const endThreshold = options.endThreshold ?? 0.015;
    const startThresholdDurationMs = options.startThresholdDuration ?? 300;
    const minSilenceDurationMs = options.minSilenceDuration ?? 800;
    const maxDuration = options.maxDuration ?? 10000;

    console.log(
      "\nğŸ™  Thresholdë¥¼ ë„˜ëŠ” ìŒì„±ì´ ì…ë ¥ë˜ë©´ ìë™ìœ¼ë¡œ ë…¹ìŒì´ ì‹œì‘ë˜ê³ , ì¹¨ë¬µì´ ì¼ì • ì‹œê°„ ìœ ì§€ë˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.",
    );

    const micInstance = mic({
      rate: String(SAMPLE_RATE),
      channels: String(CHANNELS),
      bitwidth: String(BIT_DEPTH),
      encoding: "signed-integer",
      endian: "little",
      device: options.device,
      fileType: "raw",
    });

    const micInputStream = micInstance.getAudioStream();

    const buffers = [];
    let recordingStarted = false;
    let aboveStartSec = 0;
    let belowEndSec = 0;
    let recordedMs = 0;
    let finished = false;
    let levelTimer = null;
    let visualizeLevel = false;
    const onSpeechStart = options.onSpeechStart;

    const stopRecording = (reason) => {
      if (finished) return;
      finished = true;
      micInstance.stop();
      if (levelTimer) {
        clearInterval(levelTimer);
        levelTimer = null;
      }
      process.stdout.write("\n");

      if (buffers.length === 0) {
        reject(new Error("ìŒì„± êµ¬ê°„ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."));
        return;
      }

      const pcmBuffer = Buffer.concat(buffers);
      const wav = new WaveFile();
      wav.fromScratch(CHANNELS, SAMPLE_RATE, "16", pcmBuffer);
      fs.writeFile(outputFile, Buffer.from(wav.toBuffer()), (err) => {
        if (err) {
          reject(err);
          return;
        }
        console.log(`âœ… ë…¹ìŒ ì™„ë£Œ: ${outputFile} (${reason})`);
        resolve();
      });
    };

    micInputStream.on("data", (chunk) => {
      const rms = computeRms(chunk);
      renderLevel(rms, { active: visualizeLevel });

      const chunkMs = (chunk.length / BYTES_PER_SAMPLE / SAMPLE_RATE) * 1000;
      const chunkSec = chunkMs / 1000;

      if (!recordingStarted) {
        if (rms >= startThreshold) {
          aboveStartSec += chunkSec;
          if (aboveStartSec >= startThresholdDurationMs / 1000) {
            recordingStarted = true;
            visualizeLevel = true;
            belowEndSec = 0;
            console.log("\nâ–¶ï¸  ìŒì„± ê°ì§€ë¨. ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤.");
            if (typeof onSpeechStart === "function") {
              onSpeechStart();
            }
          }
        } else {
          aboveStartSec = 0;
        }
      }

      if (recordingStarted) {
        buffers.push(Buffer.from(chunk));
        recordedMs += chunkMs;

        if (rms <= endThreshold) {
          belowEndSec += chunkSec;
          if (belowEndSec >= minSilenceDurationMs / 1000) {
            stopRecording("ì¹¨ë¬µ ê°ì§€");
          }
        } else {
          belowEndSec = 0;
        }

        if (recordedMs >= maxDuration) {
          stopRecording("ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ë„ë‹¬");
        }
      }
    });

    micInputStream.on("error", (err) => {
      if (finished) return;
      finished = true;
      micInstance.stop();
      reject(err);
    });

    micInputStream.on("startComplete", () => {
      levelTimer = setInterval(() => {}, 200);
    });

    micInputStream.on("stopComplete", () => {
      if (!finished) {
        stopRecording("ì¤‘ë‹¨ë¨");
      }
    });

    micInstance.start();

    setTimeout(() => {
      if (!finished) {
        stopRecording("ë…¹ìŒ íƒ€ì„ì•„ì›ƒ");
      }
    }, maxDuration + 2000);
  });
}
